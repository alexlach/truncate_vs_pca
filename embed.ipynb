{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from openai import OpenAI, RateLimitError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"output\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13677</th>\n",
       "      <td>Ed Harris's work in this film is up to his usu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21177</th>\n",
       "      <td>One used to say, concerning Nathaniel Hawthorn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15133</th>\n",
       "      <td>Why has this not been released? I kind of thou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>If you appreciate the renaissance in Asian hor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "13677  Ed Harris's work in this film is up to his usu...      1\n",
       "3665   It must be assumed that those who praised this...      0\n",
       "21177  One used to say, concerning Nathaniel Hawthorn...      1\n",
       "15133  Why has this not been released? I kind of thou...      1\n",
       "6597   If you appreciate the renaissance in Asian hor...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_parquet('data/train.parquet')\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19040</th>\n",
       "      <td>Shame is rather unique as a war film (or rathe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12470</th>\n",
       "      <td>This movie was terrible not only was the plot ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>Herman has made northern drama his own with Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10653</th>\n",
       "      <td>Part of the movie's low rating is the emphasis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11662</th>\n",
       "      <td>CHE! is a bad movie and deserves it reputation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "19040  Shame is rather unique as a war film (or rathe...      1\n",
       "12470  This movie was terrible not only was the plot ...      0\n",
       "7434   Herman has made northern drama his own with Li...      0\n",
       "10653  Part of the movie's low rating is the emphasis...      0\n",
       "11662  CHE! is a bad movie and deserves it reputation...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_parquet('data/test.parquet')\n",
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This embedding operation will cost a total of 1.91 USD.\n"
     ]
    }
   ],
   "source": [
    "text_emb_3_large_cost = 0.13 / 1000000  # 0.13 USD per 1M tokens\n",
    "ENCODING = tiktoken.get_encoding(\"cl100k_base\")\n",
    "emb_column = \"text\"\n",
    "encoded_text_train = ENCODING.encode(df_train[emb_column].str.cat(sep=\" \"))\n",
    "encoded_text_test = ENCODING.encode(df_test[emb_column].str.cat(sep=\" \"))\n",
    "print(f\"This embedding operation will cost a total of {(len(encoded_text_train) + len(encoded_text_test)) * text_emb_3_large_cost:.2f} USD.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "key = os.environ.get(\"API_KEY\")\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_batch(text, model=\"text-embedding-3-large\"):\n",
    "    batch_embeds = client.embeddings.create(input=text, model=model)\n",
    "    embeds = [e.embedding for e in batch_embeds.data]\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings(df):\n",
    "    batch_size = 512\n",
    "    embedding_batches = []\n",
    "    embeddings = [item for sublist in embedding_batches for item in sublist]\n",
    "    current_batch = len(embeddings) // batch_size + 1\n",
    "    total_batches = len(df) // batch_size + 1\n",
    "    for i in range(current_batch, total_batches + 1):\n",
    "        start_ind = (i - 1) * batch_size\n",
    "        end_ind = min(start_ind + batch_size - 1, len(df))\n",
    "        batch = df.loc[start_ind:end_ind, emb_column].tolist()\n",
    "        print(f\"Processing records for batch {i} from {start_ind} to {end_ind}\")\n",
    "        for j in range(10):\n",
    "            try:\n",
    "                embedding_batches.append(get_embeddings_batch(batch))\n",
    "                break\n",
    "            except RateLimitError:\n",
    "                print(f\"Rate limit error, waiting 15 seconds and trying again (attempt {j + 1})\")\n",
    "                sleep(15)\n",
    "    embeddings = [item for sublist in embedding_batches for item in sublist]\n",
    "    df[\"emb_large\"] = embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing records for batch 1 from 0 to 511\n",
      "Processing records for batch 2 from 512 to 1023\n",
      "Processing records for batch 3 from 1024 to 1535\n",
      "Processing records for batch 4 from 1536 to 2047\n",
      "Processing records for batch 5 from 2048 to 2559\n",
      "Processing records for batch 6 from 2560 to 3071\n",
      "Processing records for batch 7 from 3072 to 3583\n",
      "Processing records for batch 8 from 3584 to 4095\n",
      "Processing records for batch 9 from 4096 to 4607\n",
      "Processing records for batch 10 from 4608 to 5119\n",
      "Processing records for batch 11 from 5120 to 5631\n",
      "Processing records for batch 12 from 5632 to 6143\n",
      "Processing records for batch 13 from 6144 to 6655\n",
      "Processing records for batch 14 from 6656 to 7167\n",
      "Processing records for batch 15 from 7168 to 7679\n",
      "Processing records for batch 16 from 7680 to 8191\n",
      "Processing records for batch 17 from 8192 to 8703\n",
      "Processing records for batch 18 from 8704 to 9215\n",
      "Processing records for batch 19 from 9216 to 9727\n",
      "Processing records for batch 20 from 9728 to 10239\n",
      "Processing records for batch 21 from 10240 to 10751\n",
      "Processing records for batch 22 from 10752 to 11263\n",
      "Processing records for batch 23 from 11264 to 11775\n",
      "Processing records for batch 24 from 11776 to 12287\n",
      "Processing records for batch 25 from 12288 to 12799\n",
      "Processing records for batch 26 from 12800 to 13311\n",
      "Processing records for batch 27 from 13312 to 13823\n",
      "Processing records for batch 28 from 13824 to 14335\n",
      "Processing records for batch 29 from 14336 to 14847\n",
      "Processing records for batch 30 from 14848 to 15359\n",
      "Processing records for batch 31 from 15360 to 15871\n",
      "Processing records for batch 32 from 15872 to 16383\n",
      "Processing records for batch 33 from 16384 to 16895\n",
      "Processing records for batch 34 from 16896 to 17407\n",
      "Processing records for batch 35 from 17408 to 17919\n",
      "Processing records for batch 36 from 17920 to 18431\n",
      "Processing records for batch 37 from 18432 to 18943\n",
      "Processing records for batch 38 from 18944 to 19455\n",
      "Processing records for batch 39 from 19456 to 19967\n",
      "Processing records for batch 40 from 19968 to 20479\n",
      "Processing records for batch 41 from 20480 to 20991\n",
      "Processing records for batch 42 from 20992 to 21503\n",
      "Processing records for batch 43 from 21504 to 22015\n",
      "Processing records for batch 44 from 22016 to 22527\n",
      "Processing records for batch 45 from 22528 to 23039\n",
      "Processing records for batch 46 from 23040 to 23551\n",
      "Processing records for batch 47 from 23552 to 24063\n",
      "Processing records for batch 48 from 24064 to 24575\n",
      "Processing records for batch 49 from 24576 to 25000\n"
     ]
    }
   ],
   "source": [
    "df_train_emb = add_embeddings(df_train)\n",
    "df_train_emb.to_parquet(\"output/train_emb.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing records for batch 1 from 0 to 511\n",
      "Processing records for batch 2 from 512 to 1023\n",
      "Processing records for batch 3 from 1024 to 1535\n",
      "Processing records for batch 4 from 1536 to 2047\n",
      "Processing records for batch 5 from 2048 to 2559\n",
      "Processing records for batch 6 from 2560 to 3071\n",
      "Processing records for batch 7 from 3072 to 3583\n",
      "Processing records for batch 8 from 3584 to 4095\n",
      "Processing records for batch 9 from 4096 to 4607\n",
      "Processing records for batch 10 from 4608 to 5119\n",
      "Processing records for batch 11 from 5120 to 5631\n",
      "Processing records for batch 12 from 5632 to 6143\n",
      "Processing records for batch 13 from 6144 to 6655\n",
      "Processing records for batch 14 from 6656 to 7167\n",
      "Processing records for batch 15 from 7168 to 7679\n",
      "Processing records for batch 16 from 7680 to 8191\n",
      "Processing records for batch 17 from 8192 to 8703\n",
      "Processing records for batch 18 from 8704 to 9215\n",
      "Processing records for batch 19 from 9216 to 9727\n",
      "Processing records for batch 20 from 9728 to 10239\n",
      "Processing records for batch 21 from 10240 to 10751\n",
      "Processing records for batch 22 from 10752 to 11263\n",
      "Processing records for batch 23 from 11264 to 11775\n",
      "Processing records for batch 24 from 11776 to 12287\n",
      "Processing records for batch 25 from 12288 to 12799\n",
      "Processing records for batch 26 from 12800 to 13311\n",
      "Processing records for batch 27 from 13312 to 13823\n",
      "Processing records for batch 28 from 13824 to 14335\n",
      "Processing records for batch 29 from 14336 to 14847\n",
      "Processing records for batch 30 from 14848 to 15359\n",
      "Processing records for batch 31 from 15360 to 15871\n",
      "Processing records for batch 32 from 15872 to 16383\n",
      "Processing records for batch 33 from 16384 to 16895\n",
      "Processing records for batch 34 from 16896 to 17407\n",
      "Processing records for batch 35 from 17408 to 17919\n",
      "Processing records for batch 36 from 17920 to 18431\n",
      "Processing records for batch 37 from 18432 to 18943\n",
      "Processing records for batch 38 from 18944 to 19455\n",
      "Processing records for batch 39 from 19456 to 19967\n",
      "Processing records for batch 40 from 19968 to 20479\n",
      "Processing records for batch 41 from 20480 to 20991\n",
      "Processing records for batch 42 from 20992 to 21503\n",
      "Processing records for batch 43 from 21504 to 22015\n",
      "Processing records for batch 44 from 22016 to 22527\n",
      "Processing records for batch 45 from 22528 to 23039\n",
      "Processing records for batch 46 from 23040 to 23551\n",
      "Processing records for batch 47 from 23552 to 24063\n",
      "Processing records for batch 48 from 24064 to 24575\n",
      "Processing records for batch 49 from 24576 to 25000\n"
     ]
    }
   ],
   "source": [
    "df_test_emb = add_embeddings(df_test)\n",
    "df_test_emb.to_parquet(\"output/test_emb.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
